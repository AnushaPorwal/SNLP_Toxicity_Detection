{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c6d193",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d15859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model\n",
    "import string\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b5517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb29f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7eaeb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c026499",
   "metadata": {},
   "source": [
    "### Data import & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13f83df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_2024.csv', quoting=3)\n",
    "eval_data = pd.read_csv('data/test_2024.csv', quoting=3)\n",
    "dev_data = pd.read_csv('data/dev_2024.csv', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc5c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['text'] = train_data['text'].str.lower()\n",
    "eval_data['text'] = eval_data['text'].str.lower()\n",
    "dev_data['text'] = dev_data['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a17fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(data):\n",
    "    data['text_wo_stopwords'] = data['text'].apply(lambda x : ' '.join([word for word in x.split() if word not in stopwords]))\n",
    "    return data\n",
    "\n",
    "def remove_tags(test_str):\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for ele in test_str:\n",
    "        if ele in punc:\n",
    "            test_str = test_str.replace(ele, \"\")\n",
    "    return test_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "605bfc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_Y(data):\n",
    "    '''\n",
    "        Takes in df data\n",
    "        Processes the text in the dataframe\n",
    "        returns the texts as a list, and labels as an array\n",
    "    '''\n",
    "    data = remove_stopwords(data)\n",
    "    data['clean_text']= data['text_wo_stopwords'].apply(lambda cw : remove_tags(cw))\n",
    "    text_list = []\n",
    "    for i in range(len(data)):\n",
    "        text_list.append(data['clean_text'][i])\n",
    "\n",
    "    labels = np.array(data['label'])\n",
    "    return text_list, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afdb2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = get_X_Y(train_data)\n",
    "X_eval, Y_eval= get_X_Y(eval_data)\n",
    "X_dev, Y_dev = get_X_Y(dev_data)\n",
    "\n",
    "X_train.extend(X_dev)\n",
    "X = X_train\n",
    "Y = np.concatenate((Y_train, Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1207c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06dcf8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88000, 22000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain), len(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c10acdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_ids = np.array(eval_data['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1feb6878",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for i in xtrain:\n",
    "    words = i.split()\n",
    "    vocab.update(words)\n",
    "    \n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccb13849",
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_tok = '<OOV>'\n",
    "tokenizer = Tokenizer(num_words = vocab_size, \n",
    "                      char_level = False,\n",
    "                      oov_token = oov_tok)\n",
    "tokenizer.fit_on_texts(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cbb8cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88808"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "total_words = len(word_index)\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a25318a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen=50\n",
    "training_sequences = tokenizer.texts_to_sequences(xtrain)\n",
    "training_padded = pad_sequences(training_sequences,\n",
    "                                maxlen = maxLen,\n",
    "                                padding = 'post',\n",
    "                                truncating = 'post')\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(xtest)\n",
    "testing_padded = pad_sequences(testing_sequences,\n",
    "                               maxlen = maxLen,\n",
    "                               padding = 'post',\n",
    "                               truncating = 'post')\n",
    "\n",
    "eval_sequences = tokenizer.texts_to_sequences(X_eval)\n",
    "eval_padded = pad_sequences(eval_sequences,\n",
    "                               maxlen = maxLen,\n",
    "                               padding = 'post',\n",
    "                               truncating = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4d6a3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training tensor:  (88000, 50)\n",
      "Shape of testing tensor:  (22000, 50)\n",
      "Shape of dev tensor:  (12001, 50)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of training tensor: ', training_padded.shape)\n",
    "print('Shape of testing tensor: ', testing_padded.shape)\n",
    "print('Shape of dev tensor: ', eval_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c6eef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "\n",
    "def createLSTMmodel():\n",
    "    # Define parameter\n",
    "    n_lstm = 128\n",
    "    drop_lstm = 0.2\n",
    "    embedding_dim = 32\n",
    "    # Define LSTM Model \n",
    "    model2 = Sequential()\n",
    "    model2.add(Embedding(vocab_size, embedding_dim, input_length = maxLen))\n",
    "    model2.add(Bidirectional(LSTM(n_lstm, return_sequences = False)))\n",
    "    model2.add(Dropout(drop_lstm))\n",
    "    model2.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5b317a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 50, 32)            2843872   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 256)               164864    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3008993 (11.48 MB)\n",
      "Trainable params: 3008993 (11.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = createLSTMmodel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aef7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96f5c10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2750/2750 [==============================] - 304s 108ms/step - loss: 0.2671 - accuracy: 0.8946\n",
      "Epoch 2/10\n",
      "2750/2750 [==============================] - 199s 72ms/step - loss: 0.1612 - accuracy: 0.9413\n",
      "Epoch 3/10\n",
      "2750/2750 [==============================] - 145s 53ms/step - loss: 0.1157 - accuracy: 0.9578\n",
      "Epoch 4/10\n",
      "2750/2750 [==============================] - 146s 53ms/step - loss: 0.0798 - accuracy: 0.9710\n",
      "Epoch 5/10\n",
      "2750/2750 [==============================] - 145s 53ms/step - loss: 0.0553 - accuracy: 0.9801\n",
      "Epoch 6/10\n",
      "2750/2750 [==============================] - 146s 53ms/step - loss: 0.0374 - accuracy: 0.9863\n",
      "Epoch 7/10\n",
      "2750/2750 [==============================] - 146s 53ms/step - loss: 0.0264 - accuracy: 0.9906\n",
      "Epoch 8/10\n",
      "2750/2750 [==============================] - 146s 53ms/step - loss: 0.0201 - accuracy: 0.9929\n",
      "Epoch 9/10\n",
      "2750/2750 [==============================] - 145s 53ms/step - loss: 0.0149 - accuracy: 0.9948\n",
      "Epoch 10/10\n",
      "2750/2750 [==============================] - 156s 57ms/step - loss: 0.0115 - accuracy: 0.9959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c18ee0f790>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "#model1.fit(training_padded, Y_train, epochs=num_epochs, validation_data=(dev_padded, Y_dev), verbose=2)\n",
    "model.fit(training_padded, ytrain, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6faee16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/biLSTM_trainableEmbeds.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52cda981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 12s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_test = model.predict(testing_padded)\n",
    "ypred_test = []\n",
    "for i in range(len(preds_test)):\n",
    "    if preds_test[i] > 0.5:\n",
    "        ypred_test.append(1)\n",
    "    else:\n",
    "        ypred_test.append(0)\n",
    "        \n",
    "preds_test = np.array(preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "947f6a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8938636363636364 0.8550679659859725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "acc = accuracy_score(ytest, ypred_test)\n",
    "f1 = f1_score(ytest, ypred_test)\n",
    "print(acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05b74b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688/688 [==============================] - 12s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_test = model.predict(testing_padded)\n",
    "ypred_test = []\n",
    "for i in range(len(preds_test)):\n",
    "    if preds_test[i] > 0.5:\n",
    "        ypred_test.append(1)\n",
    "    else:\n",
    "        ypred_test.append(0)\n",
    "        \n",
    "preds_test = np.array(preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f093dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
