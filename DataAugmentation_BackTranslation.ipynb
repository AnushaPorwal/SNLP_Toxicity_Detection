{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d907d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nlpaug.augmenter.word as naw\n",
    "from nlpaug.augmenter.word import WordAugmenter\n",
    "import torch\n",
    "\n",
    "#pip install numpy requests nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44e5ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\anush\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\anush\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: boto3 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from transformers) (1.24.28)\n",
      "Requirement already satisfied: requests in c:\\users\\anush\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anush\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: regex in c:\\users\\anush\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Collecting sentencepiece (from transformers)\n",
      "  Obtaining dependency information for sentencepiece from https://files.pythonhosted.org/packages/a2/f6/587c62fd21fc988555b85351f50bbde43a51524caafd63bc69240ded14fd/sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\anush\\anaconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from boto3->transformers) (1.27.59)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from boto3->transformers) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from boto3->transformers) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: six in c:\\users\\anush\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\anush\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\anush\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anush\\anaconda3\\lib\\site-packages (from tqdm->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from botocore<1.28.0,>=1.27.28->boto3->transformers) (2.8.2)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 409.6/991.5 kB 8.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  983.0/991.5 kB 12.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 991.5/991.5 kB 10.4 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3db4c7e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AutoModelForSeq2SeqLM' from 'transformers' (C:\\Users\\anush\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSeq2SeqLM\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'AutoModelForSeq2SeqLM' from 'transformers' (C:\\Users\\anush\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a69bb4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'The quick brown fox jumped over the lazy dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2911cc18",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AutoModelForSeq2SeqLM' from 'transformers' (C:\\Users\\anush\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m back_translation_aug \u001b[38;5;241m=\u001b[39m naw\u001b[38;5;241m.\u001b[39mBackTranslationAug(\n\u001b[0;32m      2\u001b[0m     from_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer.wmt19.en-de\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m     to_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer.wmt19.de-en\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nlpaug\\augmenter\\word\\back_translation.py:61\u001b[0m, in \u001b[0;36mBackTranslationAug.__init__\u001b[1;34m(self, from_model_name, to_model_name, name, device, batch_size, max_length, force_reload, verbose)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, from_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebook/wmt19-en-de\u001b[39m\u001b[38;5;124m'\u001b[39m, to_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebook/wmt19-de-en\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     56\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBackTranslationAug\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, force_reload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     58\u001b[0m         action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubstitute\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39mname, aug_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aug_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aug_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     59\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice, verbose\u001b[38;5;241m=\u001b[39mverbose, include_detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model(from_model_name\u001b[38;5;241m=\u001b[39mfrom_model_name, to_model_name\u001b[38;5;241m=\u001b[39mto_model_name, \n\u001b[0;32m     62\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, max_length\u001b[38;5;241m=\u001b[39mmax_length\n\u001b[0;32m     63\u001b[0m     )\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nlpaug\\augmenter\\word\\back_translation.py:76\u001b[0m, in \u001b[0;36mBackTranslationAug.get_model\u001b[1;34m(cls, from_model_name, to_model_name, device, force_reload, batch_size, max_length)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model\u001b[39m(\u001b[38;5;28mcls\u001b[39m, from_model_name, to_model_name, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, force_reload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     75\u001b[0m               batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m init_back_translation_model(from_model_name, to_model_name, device,\n\u001b[0;32m     77\u001b[0m         force_reload, batch_size, max_length)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nlpaug\\augmenter\\word\\back_translation.py:25\u001b[0m, in \u001b[0;36minit_back_translation_model\u001b[1;34m(from_model_name, to_model_name, device, force_reload, batch_size, max_length)\u001b[0m\n\u001b[0;32m     21\u001b[0m     BACK_TRANSLATION_MODELS[model_name]\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m=\u001b[39m max_length\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BACK_TRANSLATION_MODELS[model_name]\n\u001b[1;32m---> 25\u001b[0m model \u001b[38;5;241m=\u001b[39m nml\u001b[38;5;241m.\u001b[39mMtTransformers(src_model_name\u001b[38;5;241m=\u001b[39mfrom_model_name, tgt_model_name\u001b[38;5;241m=\u001b[39mto_model_name, \n\u001b[0;32m     26\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, max_length\u001b[38;5;241m=\u001b[39mmax_length)\n\u001b[0;32m     28\u001b[0m BACK_TRANSLATION_MODELS[model_name] \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nlpaug\\model\\lang_models\\machine_translation_transformers.py:17\u001b[0m, in \u001b[0;36mMtTransformers.__init__\u001b[1;34m(self, src_model_name, tgt_model_name, device, silence, batch_size, max_length)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(device, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, silence\u001b[38;5;241m=\u001b[39msilence)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSeq2SeqLM\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissed transformers library. Install transfomers by `pip install transformers`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'AutoModelForSeq2SeqLM' from 'transformers' (C:\\Users\\anush\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "back_translation_aug = naw.BackTranslationAug(\n",
    "    from_model_name='transformer.wmt19.en-de',\n",
    "    to_model_name='transformer.wmt19.de-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f52606",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_translation_aug.augment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e7475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACK_TRANSLATION_MODELS = {}\n",
    "\n",
    "\n",
    "def init_back_translation_model(from_model_name, to_model_name, device, force_reload=False,\n",
    "                                batch_size=32, max_length=None):\n",
    "    global BACK_TRANSLATION_MODELS\n",
    "\n",
    "    model_name = '_'.join([from_model_name, to_model_name, str(device)])\n",
    "    if model_name in BACK_TRANSLATION_MODELS and not force_reload:\n",
    "        BACK_TRANSLATION_MODELS[model_name].batch_size = batch_size\n",
    "        BACK_TRANSLATION_MODELS[model_name].max_length = max_length\n",
    "\n",
    "        return BACK_TRANSLATION_MODELS[model_name]\n",
    "\n",
    "    model = nml.MtTransformers(src_model_name=from_model_name, tgt_model_name=to_model_name, \n",
    "        device=device, batch_size=batch_size, max_length=max_length)\n",
    "\n",
    "    BACK_TRANSLATION_MODELS[model_name] = model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8716d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, from_model_name='facebook/wmt19-en-de', to_model_name='facebook/wmt19-de-en',\n",
    "        name='BackTranslationAug', device='cpu', batch_size=32, max_length=300, force_reload=False, verbose=0):\n",
    "        super().__init__(\n",
    "            action='substitute', name=name, aug_p=None, aug_min=None, aug_max=None, tokenizer=None,\n",
    "            device=device, verbose=verbose, include_detail=False)\n",
    "\n",
    "        self.model = self.get_model(from_model_name=from_model_name, to_model_name=to_model_name, \n",
    "            device=device, batch_size=batch_size, max_length=max_length\n",
    "        )\n",
    "        self.device = self.model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84b530eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute(self, data, n=1):\n",
    "        if not data:\n",
    "            return data\n",
    "\n",
    "        augmented_text = self.model.predict(data)\n",
    "        return augmented_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60eb88d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackTranslationAug(WordAugmenter):\n",
    "    # https://arxiv.org/pdf/1511.06709.pdf\n",
    "    \"\"\"\n",
    "    Augmenter that leverage two translation models for augmentation. For example, the source is English. This\n",
    "    augmenter translate source to German and translating it back to English. For detail, you may visit\n",
    "    https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28\n",
    "\n",
    "    :param str from_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP. As\n",
    "        long as from_model_name is pair with to_model_name. For example, from_model_name is English to Japanese,\n",
    "        then to_model_name should be Japanese to English.\n",
    "    :param str to_model_name: Any model from https://huggingface.co/models?filter=translation&search=Helsinki-NLP.\n",
    "    :param str device: Default value is CPU. If value is CPU, it uses CPU for processing. If value is CUDA, it uses GPU\n",
    "        for processing. Possible values include 'cuda' and 'cpu'. (May able to use other options)\n",
    "    :param bool force_reload: Force reload the contextual word embeddings model to memory when initialize the class.\n",
    "        Default value is False and suggesting to keep it as False if performance is the consideration.\n",
    "    :param int batch_size: Batch size.\n",
    "    :param int max_length: The max length of output text.\n",
    "    :param str name: Name of this augmenter\n",
    "\n",
    "    >>> import nlpaug.augmenter.word as naw\n",
    "    >>> aug = naw.BackTranslationAug()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, from_model_name='facebook/wmt19-en-de', to_model_name='facebook/wmt19-de-en',\n",
    "        name='BackTranslationAug', device='cpu', batch_size=32, max_length=300, force_reload=False, verbose=0):\n",
    "        super().__init__(\n",
    "            action='substitute', name=name, aug_p=None, aug_min=None, aug_max=None, tokenizer=None,\n",
    "            device=device, verbose=verbose, include_detail=False)\n",
    "\n",
    "        self.model = self.get_model(from_model_name=from_model_name, to_model_name=to_model_name, \n",
    "            device=device, batch_size=batch_size, max_length=max_length\n",
    "        )\n",
    "        self.device = self.model.device\n",
    "\n",
    "    def substitute(self, data, n=1):\n",
    "        if not data:\n",
    "            return data\n",
    "\n",
    "        augmented_text = self.model.predict(data)\n",
    "        return augmented_text\n",
    "\n",
    "    @classmethod\n",
    "    def get_model(cls, from_model_name, to_model_name, device='cuda', force_reload=False,\n",
    "                  batch_size=32, max_length=None):\n",
    "        return init_back_translation_model(from_model_name, to_model_name, device,\n",
    "            force_reload, batch_size, max_length)\n",
    "\n",
    "    @classmethod\n",
    "    def clear_cache(cls):\n",
    "        global BACK_TRANSLATION_MODELS\n",
    "        BACK_TRANSLATION_MODELS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "981cc6fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AutoModelForSeq2SeqLM' from 'transformers' (C:\\Users\\anush\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m aug \u001b[38;5;241m=\u001b[39m naw\u001b[38;5;241m.\u001b[39mBackTranslationAug()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nlpaug\\augmenter\\word\\back_translation.py:61\u001b[0m, in \u001b[0;36mBackTranslationAug.__init__\u001b[1;34m(self, from_model_name, to_model_name, name, device, batch_size, max_length, force_reload, verbose)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, from_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebook/wmt19-en-de\u001b[39m\u001b[38;5;124m'\u001b[39m, to_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebook/wmt19-de-en\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     56\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBackTranslationAug\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, force_reload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     58\u001b[0m         action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubstitute\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39mname, aug_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aug_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aug_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     59\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice, verbose\u001b[38;5;241m=\u001b[39mverbose, include_detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model(from_model_name\u001b[38;5;241m=\u001b[39mfrom_model_name, to_model_name\u001b[38;5;241m=\u001b[39mto_model_name, \n\u001b[0;32m     62\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, max_length\u001b[38;5;241m=\u001b[39mmax_length\n\u001b[0;32m     63\u001b[0m     )\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nlpaug\\augmenter\\word\\back_translation.py:76\u001b[0m, in \u001b[0;36mBackTranslationAug.get_model\u001b[1;34m(cls, from_model_name, to_model_name, device, force_reload, batch_size, max_length)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model\u001b[39m(\u001b[38;5;28mcls\u001b[39m, from_model_name, to_model_name, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, force_reload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     75\u001b[0m               batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m init_back_translation_model(from_model_name, to_model_name, device,\n\u001b[0;32m     77\u001b[0m         force_reload, batch_size, max_length)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nlpaug\\augmenter\\word\\back_translation.py:25\u001b[0m, in \u001b[0;36minit_back_translation_model\u001b[1;34m(from_model_name, to_model_name, device, force_reload, batch_size, max_length)\u001b[0m\n\u001b[0;32m     21\u001b[0m     BACK_TRANSLATION_MODELS[model_name]\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m=\u001b[39m max_length\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BACK_TRANSLATION_MODELS[model_name]\n\u001b[1;32m---> 25\u001b[0m model \u001b[38;5;241m=\u001b[39m nml\u001b[38;5;241m.\u001b[39mMtTransformers(src_model_name\u001b[38;5;241m=\u001b[39mfrom_model_name, tgt_model_name\u001b[38;5;241m=\u001b[39mto_model_name, \n\u001b[0;32m     26\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, max_length\u001b[38;5;241m=\u001b[39mmax_length)\n\u001b[0;32m     28\u001b[0m BACK_TRANSLATION_MODELS[model_name] \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nlpaug\\model\\lang_models\\machine_translation_transformers.py:17\u001b[0m, in \u001b[0;36mMtTransformers.__init__\u001b[1;34m(self, src_model_name, tgt_model_name, device, silence, batch_size, max_length)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(device, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, silence\u001b[38;5;241m=\u001b[39msilence)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSeq2SeqLM\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissed transformers library. Install transfomers by `pip install transformers`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'AutoModelForSeq2SeqLM' from 'transformers' (C:\\Users\\anush\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "aug = naw.BackTranslationAug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad749ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7234d22e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
